
* Термины k8s

- Cluster состоит из Nodes
- Каждая Node содержит Pods
- Pod - это один или группа (тесно связанных) Container. Used to orchestrate containers in cloud
- Deployments: used to provide scalability and zero-downtime updates
- Services and Ingress: provide access to applications

- Service is a method for exposing an application that consists of one or more replicated Pods.
Service Types:
= ClusterIP: the default type, exposes an application on a cluster internal IP address only.
= NodePort: uses a cluster internal IP address that is made accessible on cluster nodes through port forwarding.
= LoadBalancer: exposes the Service externally using an external load balancer.
= ExternalName: forwards traffic to an external DNS name instead of Pods.

- Ingress is cluster integrated load balancer. It's basically http/https proxy
- ConfigMap: stores configuration in a decoupled way
- Persistent Volumes: used to store data in a decoupled way


# Список команд во время прохождения курса Богдана Стащука "Полный Курс по Kubernetes"

kubectl version --client --output=yaml
choco install minikube
choco upgrade minikube

minikube help
minikube start
minikube delete

minikube kubectl cluster-info
kubectl get nodes
kubectl get namespaces
kubectl get pods --namespace=kube-system
minikube ip
minikube ssh
docker ps
kubectl run my-nginx-pod --image=nginx
kubectl get pods
kubectl describe pod my-nginx-pod

minikube ssh
ping 10.244.0.3
curl 10.244.0.3
docker ps | grep nginx

docker exec -it 3352b sh	# 3352b - it's (part of) container id
hostname		# show container name
hostname -I		# show ip address of container (== ip address of pod)

alias k="minikube kubectl --"

k get pods -o wide
k delete pod my-nginx-pod
k get pods

k create deployment my-nginx-deploy --image=nginx
k describe deploy my-nginx-deploy
k get pods
k describe pod my-nginx-deploy-75488fc988-gvlxk  # my-nginx-deploy-75488fc988 == ID of replica set

k get pods
k scale deploy my-nginx-deploy --replicas=3
k get pods
k scale deploy my-nginx-deploy --replicas=10
k get pods
k scale deploy my-nginx-deploy --replicas=4
k get pods
k describe deploy my-nginx-deploy

k get pods -o wide	# to show ip addresses of pods
k describe deploy my-nginx-deploy	# show events log for this deployment

k delete pod my-nginx-deploy-75488fc988-8nk2t
k get pods
k get deploy

k get services
k describe service kubernetes	# describe details of system service
k expose deploy my-nginx-deploy --port=8080 --target-port=80
k get svc
k describe svc my-nginx-deploy
minikube ssh
logout
k get svc

# create сервиса типа NodePort (ранее тип был ClusterIP)
k delete svc my-nginx-deploy
k get svc
k expose deploy my-nginx-deploy --type=NodePort --port=8888 --target-port=80
k get svc
k describe svc my-nginx-deploy
minikube ip
curl 192.168.49.2:30614		# result wil be negative
minikube service my-nginx-deploy --url	# created tunnel to the service my-nginx-deploy
k get svc
k delete svc my-nginx-deploy
k get svc

minikube tunnel
k expose deploy my-nginx-deploy --type=LoadBalancer --port=9999 --target-port=80
k get svc

k get deploy
k get pods
k get svc

service types: ClusterIP, NodePort, LoadBalancer
k delete svc my-nginx-deploy
k delete deploy my-nginx-deploy
k get pods
k get deploy
k get svc

choco install nodejs
node --version
npm --version

docker build . -t andd3dfx/k8s-web-hello-ru:latest -t andd3dfx/k8s-web-hello-ru:1.0.0
docker images | grep web-hello
docker login
docker push andd3dfx/k8s-web-hello-ru
docker push andd3dfx/k8s-web-hello-ru --all-tags

k create deploy k8s-web-hello --image=andd3dfx/k8s-web-hello-ru:1.0.0
k get pods
k describe deploy k8s-web-hello
k get pods
k describe pod k8s-web-hello-fcf469d87-7lmzf	# `k8s-web-hello-fcf469d87` - replica set, `7lmzf` - id of pod
k get pods -o wide
minikube ssh
curl 10.244.0.15:3000
curl 10.244.0.15:3000; echo 	# to add new line after console output
k get svc

k get deploy
k get pods

minikube tunnel		# started tunnel
# in another terminal:
k expose deploy k8s-web-hello --type=LoadBalancer --port=3333 --target-port=3000
k get svc
open http://localhost:3333/ in browser
k get pods
k describe svc k8s-web-hello
k scale deploy k8s-web-hello --replicas=7
k get pods
after refreshing http://localhost:3333/ in browser we get answers from different pods
k get deploy
k describe deploy k8s-web-hello

docker build . -t andd3dfx/k8s-web-hello-ru:latest -t andd3dfx/k8s-web-hello-ru:2.0.0
docker push andd3dfx/k8s-web-hello-ru --all-tags
k get svc

k rollout status deploy k8s-web-hello
minikube ssh
docker ps | grep web-hello
exit
k set image deploy k8s-web-hello k8s-web-hello-ru=andd3dfx/k8s-web-hello-ru:2.0.0
open http://localhost:3333/ in browser	# refresh several times
k get pods
k describe deploy k8s-web-hello
k set image deploy k8s-web-hello k8s-web-hello-ru=andd3dfx/k8s-web-hello-ru:1.0.0
open http://localhost:3333/ in browser	# refresh several times
k get pods
k set image deploy k8s-web-hello k8s-web-hello-ru=andd3dfx/k8s-web-hello-ru:2.0.0
k scale deploy k8s-web-hello --replicas=20
k get pods
k scale deploy k8s-web-hello --replicas=4
k get pods

k delete svc k8s-web-hello
http://localhost:3333/ became unavaliable
k get pods -o wide
minikube ssh
curl 10.244.0.40:3000
exit
k delete deploy k8s-web-hello

k apply -f deployment.yaml
k get deploy
k describe deploy k8s-web-hello
minikube dashboard
k delete -f deployment.yaml -f service.yaml

docker build . -t andd3dfx/k8s-web-to-nginx-ru
docker images | grep k8s-web
docker push andd3dfx/k8s-web-to-nginx-ru
k apply -f k8s-web-to-nginx.yaml -f nginx.yaml 
k get deploy
k get svc
k get pods
k describe pod k8s-web-to-nginx-7c5d5d88ff-fj4wk
minikube tunnel		# now check output of `k get svc`
minikube dashboard
check http://localhost:3333/ in browser

k get svc
minikube ssh
curl 10.96.144.4
curl nginx			# could not get response be name
docker ps | grep k8s-web-to-nginx
docker exec -it 17a7c577c6a0 sh		# enter inside container
wget 10.96.144.4	# same result as previous curl
rm index.html
wget nginx			# now successful
nslookup nginx	# response from DNS server
exit
exit
k get svc

k apply -f k8s-web-to-nginx.yaml -f nginx.yaml
k get pods

docker images | grep k8s-web-to-nginx
docker tag andd3dfx/k8s-web-to-nginx-ru:latest andd3dfx/k8s-web-to-nginx-ru:1.0.0
docker images | grep k8s-web-to-nginx
docker push andd3dfx/k8s-web-to-nginx-ru --all-tags

k delete -f k8s-web-to-nginx.yaml -f nginx.yaml
k get pods
k get svc
minikube status
minikube stop
minikube delete

minikube start --driver=hyperv --container-runtime=containerd
minikube status
minikube ssh
docker ps	# docker shoule not be present
sudo ctr -n k8s.io containers list

minikube tunnel
k apply -f k8s-web-to-nginx.yaml -f nginx.yaml
k get deploy
k get svc
k get pods
curl http://10.106.200.31:3333

minikube ssh
sudo ctr -n k8s.io containers list | grep nginx
k get svc
k delete -f k8s-web-to-nginx.yaml -f nginx.yaml
minikube stop
minikube delete

-----------------------------------

* Заметки в ходе курса "Kubernetes Step-by-Step"

kubectl create deploy myapp --image=nginx --replicas=2 --dry-run=client -o yaml > myapp.yaml	#generate YAML code for new deployment
kubectl get <k8s-app-name> -o yaml		#show YAML code that is behind an application currently running
use `kubectl explain` on any resource to discover its parameters, for example:
kubectl explain deploy.spec
kubectl explain pod.spec

strategy (of applying update):
	-RollingUpdate	#during process of deployment new version - some pods have old version, some - new version
	-Recreate		#pods with old version deleted, after that new pods with new version created, so no two version at the same time

kubectl logs <pod-name>		#show logs of pod

kubectl set env deploy <deploy-name> KEY=VALUE	#set env variable for pod

# The label is set to app equals to name of the application
kubectl get all --show-labels	#added label app=... to each line of report, 
								#it's useful to determine what's happening, so we could reduce output using:
kubectl get all --selector app=<label-name>		# it shows only apps with label <label-name>

Storing environment configuration in Git has name: GitOps.

kubectl get deploy <deploy-name> -o yaml | less		# to show current deploy in YAML format

source <(kubectl completion bash) 	#to add completion ability in cmd

kubectl expose deploy <deploy-name> --port=80 --type=NodePort	#expose port
kubectl get deploy,pods,svc --show-labels -o wide

minikube ip		# show minikube node ip address

Ingress is optional component.
Ingress exposes HTTP and HTTPS routes from outside the cluster to Services within the cluster.
To do so, a load balancer provided by the Ingress controller is used.
Ingress connects to a Service to discover the Pods that it exposes.
To work with Ingress, the Ingress controller must be installed separately.

minikube addons list			#show addons list
minikube addons enable ingress	#enable ingress addon

kubectl get ns					#show avaliable namespaces
kubectl get pods -n ingress-nginx	#show pods in ingress namespace

sudo sh -c "echo $(minikube ip) myweb.example.com >> /etc/hosts"	#addition of ip to hosts
kubectl create ing myweb --rule="myweb.example.com/=myweb:80"		#create ingress resource, specify the rule that all trafic to myweb.example.com should going to myweb, port 80. so it's `name-based virtual hosting`

kubectl describe ing myweb		#to verify it
curl myweb.example.com			#make test request

kubectl get all

#example of file creation inside folder on pod volume, and inspection of its existence:
kubectl exec podvol -c busybox1 -- touch /busy1/testfile
kubectl exec podvol -c busybox2 -- ls /busy2

A Persistence Volume (PV) is a separate API resource that represents storage in a specific environment
A Persistence Volume Claim (PVC) is an API object that dynamically discovers available Persistent Volumes, without asking for a specific solution

kubectl get pv,pvc,pods
kubectl exec local-pv-pod -- touch /usr/share/nginx/html/testfile
kubectl describe pv local-pv-volume
minikube ssh
ls /mnt/data

kubectl get storageclass
kubectl describe storageclass standard
kubectl get pods -n kube-system
kubectl get pv,pvc

kubectl get storageclass
kubectl apply -f lab6-pvc.yaml
kubectl get pvc
kubectl describe pvc lab6-pvc
kubectl delete -f lab6-pvc.yaml
kubectl apply -f lab6-pvc.yaml

kubectl run busytest --image=busybox --dry-run=client -o yaml -- sleep 3600		# without command to execute after start - busybox will closed, so need to add this command

kubectl create cm --help | less		#show help for `create ConfigMap` command
# different examples of configmap creation:
kubectl create configmap my-config --from-file=/path/to/bar		#from folder
kubectl create configmap my-config --from-file=/path/to/bar/file1.txt --from-file=/path/to/bar/file2.txt	#from keys specified in files
kubectl create configmap my-config --from-literal=key1=config1 --from-literal=key2=config2	#from key-value pairs
kubectl create configmap my-config --from-file=/path/to/bar.env		#from .env file

kubectl create cm mydbvars --from-literal=MARIADB_ROOT_PASSWORD=password
kubectl describe cm mydbvars	#check configmap content
kubectl create deploy mynewdb --image=mariadb
kubectl get all --selector app=mynewdb
kubectl set env --from=configmap/mydbvars deploy mynewdb
kubectl get all --selector app=mynewdb
kubectl get pods mynewdb[Tab] -o yaml	#show pod configuration

kubectl create deploy mynewweb --image=nginx
kubectl edit deployments.apps mynewweb

Secret types:
= generic secret type is used as a base-64 encoded ConfigMap
= TLS secret is used to store TLS keys
= docker-registry secret is used to store container registry access credentials

kubectl create secret generic mysecretdbpw --from-literal=MARIADB_ROOT_PASSWORD=password
kubectl get secret mysecretdbpw -o yaml
kubectl set env --from=secret/mysecretdbpw deploy mydb
kubectl get pod mydb[Tab] -o yaml | less

echo cGFzc3dvcmQ= | base64 -d	#decode base-64 encoded password

# Creating Secrets that have Registry Credentials
= use `docker login` to login and provide registry access credentials
= use `kubectl create secret docker-registry regcred --from-file=.dockerconfigjson=~/.docker/config.json`
= add the following in spec.template.spec of sleepy.yaml:
imagePullSecrets:
-name: regcreds
= kubectl apply -f sleepy.yaml

kubectl get secret regcred -o yaml
kubectl create deploy sleepy --image=busybox --dry-run=client -o yaml -- sleep infinity > sleepy.yaml
kubectl apply -f sleepy.yaml

In a microservice, container-based standardized components are used, and site-specific information is provided using different Kubernetes components:
= Services for accessibility
= ConfigMaps for configuration and variables
= Secrets for sensitive values
= Persistent Volumes for storage

Kubernetes Microservices can be created in different ways:
= By specifying all in one or more YAML manifest files
= Using Helm charts, where standardized components can be used and customization can be added in a flexible way
= Using Kustomization, where YAML manifest files are merged with site-specific information which may be generated dynamically
Using Helm charts or Kustomization is preferred because of the flexible way in which site-specific information and generic code are decoupled

Helm is used to streamline installing and managing Kubernetes packages.
You could see it as "package manager for Kubernetes".

# Install Helm:
github.com/helm/helm/releases
tar xvf helm[Tab]
sudo mv linux-amd64/helm /usr/local/bin
helm version

Chart is a Helm package, which contains package description and one or more templates containing Kubernetes manifest files.

To use Helm, next steps need to be performed:
= (optional) add repositories
= find charts to install
= install charts
= manage installed apps

Main site for finding Helm charts: https://artifacthub.io

# For example, to run Kubernetes Dashboard:
helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard
helm install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard
# The last command creates local app "kubernetes-dashboard" by installing the app "kubernetes-dashboard" from the repo "kubernetes-dashboard".

helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo list
helm search repo bitnami 	#searches for the word `bitnami`
helm search repo file		#searches for the word `file`
helm search repo nginx --versions	#shows different versions
helm repo update
helm install <name> <chart>	#install the chart with default params (<chart> - name in remote repo, <name> - is local name)
helm list			#list currently installed Helm charts
helm delete <name>	#remove Helm chart

# Installing Helm Charts
helm install bitnami/mysql --generate-name
kubectl get all
helm show chart bitnami/mysql
helm show all bitnami/mysql
helm list [--all-namespaces]
helm status mysql-xxxx

A Helm chart consists of templates to which specific values are applied

helm show values
# read docs on artifacthub.io for a list of all values

#create custom values.yaml which will be merged with generic file:
helm install ... --values values.yaml

#overriding values while installing:
helm install ... --set key=value

#Best practice: use a values.yaml file and only use --set when absolutely necessary

# Providing custom values
helm repo add bitnami https://charts.bitnami.com/bitnami
helm show values bitnami/nginx
helm show values bitnami/nginx | grep commonLabels
helm show values bitnami/nginx | grep replicaCount
vim values.yaml
	commonLabels: "type: helmapp"
	replicaCount: 3
helm install bitnami/nginx --generate-name --values values.yaml
helm list
helm get values nginx-xxxx			# show custom values only
helm get values --all nginx-xxxx 	# show all values

Kustomize - tool that helps manage Kubernetes configurations
= To use it - a file with the name kustomization.yaml need to be created.
= This file contains a resources section that refers to additional YAML files that need to be included, as well as optional configMapGenerator and secretGenerator.
= Apply content of this file using `kubectl apply -k .` from the directory that contains the kustomization.yaml

-----

* Минимальный набор компонентов кластера:
Control plane:
= apiserver
= controller-manager
= kube-scheduler
= etcd

Worker nodes:
= kubelet
= kube-proxy
